# Variational Auto-encoder

##  Question: 1) how to define the latent variables z (i.e., decide what information they
represent), and 2) how to deal with the integral over z. 

1)They assume that there is no simple interpretation
of the dimensions of z, and instead assert that samples of z can be drawn
from a simple distribution , i.e., N ( 0, I )
* The key is to notice that any distribution in d dimensions can
be generated by taking a set of d variables that are normally distributed and
mapping them through a sufficiently complicated function
* For example, say we wanted to construct a 2D random variable whose values lie on a
ring. If z is 2D and normally distributed, g ( z ) = z/10 + z/ || z || is roughly
ring-shaped
* In fact, recall that P ( X | z; θ ) = N ( X | f ( z; θ ) , σ 2 ∗ I ) . If f ( z; θ ) is a multi-layer neural network(Encoder),
then we can imagine the network using its first few layers to map the normally distributed z’s to the latent values with exactly the right statitics. Then it can use later layers (Decoder) to map
those latent values to a fully-rendered digit.

2) It is actually conceptually straightforward to compute P ( X ) approximately: we first sample a large
number of z values { z 1 , ..., z n } , and compute P ( X ) ≈ n 1 ∑ i P ( X | z i ) . The problem here is that in high dimensional spaces, n might need to be extremely
large before we have an accurate estimate of P ( X ) .
* Even if our model is an accurate generator of digits, we would likely need to
sample many thousands of digits before we produce a X' that is sufficiently
similar to the X. VAEs alter the sampling procedure to make it faster, without changing the similarity
metric.

## Setting up Objective (The relationship between E z ∼ q P ( X | z ) and P ( X ))
1) D [ Q ( z ) || P ( z | X )] = E z ∼ Q [ log Q ( z ) − log P ( z | X )]
2) By applying Bayes Rule: log P ( X ) − D [ Q ( z ) || P ( z | X )] = E z ∼ Q [ log P ( X | z )] − D [ Q ( z )|| P ( z )]
3) Adding dependency on X for Q:  **log P ( X ) − D [ Q ( z|X ) || P ( z | X )] = E z ∼ Q [ log P ( X | z )] − D [ Q ( z|X )|| P ( z )]**
